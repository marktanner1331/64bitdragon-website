decision trees suffer from the problem of balancing underfitting and overfitting

while this can be minimized by adjusting the maximum data per leaf node, there still exists the problem that coincidences will be captured in the trained data

a random forest is a different model, which can overcome this

a random forest is made up of lots of decision trees

its prediction is an average of the prediction of each of the trees

random trees are very widely used because they can be used for both classification and regression tasks. and they are simple

each decision tree gets a random subset of features

you can make it more random by adding random thresholds for the features as well

biggest problem with random forests is that they are slow
    especially if you have a large number of trees
