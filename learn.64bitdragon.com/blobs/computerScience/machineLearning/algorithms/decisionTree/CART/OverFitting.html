breaking data into decision trees

the more splits we have means the less data in each group (each leaf)

the prediction for each leaf will be closer to the real target for the trained data

however it will not lead to accurate predictions as its prediction is based on a smaller amount of data

this is called overfitting. in its extreme, there will be a single leaf for each item that will perfectly predict it.
this does not cope well with making predictions on new data

capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or
